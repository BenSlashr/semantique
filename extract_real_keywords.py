#!/usr/bin/env python3
"""
Extraction rÃ©elle des mots-clÃ©s via ValueSERP et SEOAnalyzer
"""

import asyncio
from services.valueserp_service import ValueSerpService
from services.seo_analyzer import SEOAnalyzer
import os
import time

class RealKeywordExtractor:
    def __init__(self):
        self.valueserp_service = ValueSerpService()
        self.seo_analyzer = SEOAnalyzer()
    
    def check_api_key(self):
        """VÃ©rifie la prÃ©sence de la clÃ© API"""
        api_key = os.getenv("VALUESERP_API_KEY") or os.getenv("SERP_API_KEY")
        
        if not api_key:
            print("âŒ ERREUR: ClÃ© API ValueSERP introuvable")
            print("ğŸ” Variables d'environnement vÃ©rifiÃ©es:")
            print("   - VALUESERP_API_KEY")
            print("   - SERP_API_KEY") 
            print("\nğŸ’¡ Veuillez fournir votre clÃ© API ValueSERP")
            return None
        
        print(f"âœ… ClÃ© API trouvÃ©e: {api_key[:10]}...{api_key[-4:]}")
        return api_key
    
    async def extract_keywords_for_query(self, query: str) -> dict:
        """Extraction complÃ¨te des mots-clÃ©s pour une requÃªte"""
        
        print(f"\n{'='*80}")
        print(f"ğŸ¯ EXTRACTION RÃ‰ELLE: '{query}'")
        print(f"{'='*80}")
        
        try:
            start_time = time.time()
            
            # Ã‰TAPE 1: RÃ©cupÃ©ration SERP via ValueSERP
            print(f"\nğŸ“¡ Ã‰TAPE 1: RÃ©cupÃ©ration SERP...")
            serp_results = await self.valueserp_service.get_serp_data(query, "France", "fr")
            
            if not serp_results or not serp_results.get('organic_results'):
                print(f"âŒ Aucun rÃ©sultat SERP pour '{query}'")
                return {'query': query, 'status': 'no_serp', 'error': 'Aucun rÃ©sultat SERP'}
            
            organic_results = serp_results.get('organic_results', [])
            paa_questions = serp_results.get('paa', [])
            related_searches = serp_results.get('related_searches', [])
            
            print(f"âœ… SERP rÃ©cupÃ©rÃ©s:")
            print(f"   ğŸ“ RÃ©sultats organiques: {len(organic_results)}")
            print(f"   â“ Questions PAA: {len(paa_questions)}")
            print(f"   ğŸ”— Recherches associÃ©es: {len(related_searches)}")
            
            # Ã‰TAPE 2: Analyse sÃ©mantique avec SEOAnalyzer
            print(f"\nğŸ§  Ã‰TAPE 2: Analyse sÃ©mantique SEOAnalyzer...")
            
            analysis_results = await self.seo_analyzer.analyze_competition(query, serp_results)
            
            analysis_time = time.time() - start_time
            print(f"âœ… Analyse terminÃ©e en {analysis_time:.2f}s")
            
            # Ã‰TAPE 3: Structuration des rÃ©sultats
            return {
                'query': query,
                'status': 'success',
                'analysis_time': round(analysis_time, 2),
                'serp_data': {
                    'organic_count': len(organic_results),
                    'paa_questions': paa_questions,
                    'related_searches': related_searches,
                    'top_competitors': [
                        {
                            'position': r.get('position'),
                            'domain': r.get('domain', ''),
                            'title': r.get('title', ''),
                            'url': r.get('url', '')
                        }
                        for r in organic_results[:5]
                    ]
                },
                'seo_analysis': {
                    'target_seo_score': analysis_results.get('score_cible', 0),
                    'recommended_words': analysis_results.get('mots_requis', 0),
                    'max_overoptimization': analysis_results.get('max_suroptimisation', 0),
                    'required_keywords': [
                        {
                            'keyword': kw[0],
                            'frequency': kw[1],
                            'importance': kw[2],
                            'min_freq': kw[3],
                            'max_freq': kw[4]
                        }
                        for kw in analysis_results.get('KW_obligatoires', [])[:15]
                    ],
                    'complementary_keywords': [
                        {
                            'keyword': kw[0], 
                            'frequency': kw[1],
                            'importance': kw[2],
                            'min_freq': kw[3],
                            'max_freq': kw[4]
                        }
                        for kw in analysis_results.get('KW_complementaires', [])[:15]
                    ],
                    'ngrams': [
                        {
                            'ngram': ng[0],
                            'frequency': ng[1],
                            'importance': ng[2]
                        }
                        for ng in analysis_results.get('ngrams', [])[:10]
                    ],
                    'market_analysis': analysis_results.get('types_contenu', {}),
                    'generated_questions': analysis_results.get('questions', '')
                }
            }
            
        except Exception as e:
            print(f"âŒ Erreur lors de l'extraction: {e}")
            return {
                'query': query,
                'status': 'error', 
                'error': str(e)
            }
    
    def display_keyword_results(self, results: dict):
        """Affiche les rÃ©sultats de maniÃ¨re structurÃ©e"""
        
        if results['status'] != 'success':
            print(f"âŒ Ã‰chec pour '{results['query']}': {results.get('error', 'Erreur inconnue')}")
            return
        
        query = results['query']
        serp = results['serp_data']
        seo = results['seo_analysis']
        
        print(f"\nğŸ“Š RÃ‰SULTATS POUR '{query.upper()}'")
        print("=" * 80)
        
        # Informations gÃ©nÃ©rales
        print(f"â±ï¸  Temps d'analyse: {results['analysis_time']}s")
        print(f"ğŸ“ Concurrents analysÃ©s: {serp['organic_count']}")
        print(f"ğŸ¯ Score SEO cible: {seo['target_seo_score']}")
        print(f"ğŸ“Š Mots recommandÃ©s: {seo['recommended_words']}")
        print(f"âš ï¸  Max suroptimisation: {seo['max_overoptimization']}%")
        
        # TOP 5 Concurrents
        print(f"\nğŸ† TOP 5 CONCURRENTS:")
        for comp in serp['top_competitors']:
            if comp['domain']:
                print(f"   #{comp['position']} {comp['domain']:<25} {comp['title'][:50]}...")
        
        # MOTS-CLÃ‰S OBLIGATOIRES (Primaires)
        print(f"\nğŸ¯ MOTS-CLÃ‰S PRIMAIRES (OBLIGATOIRES):")
        if seo['required_keywords']:
            for i, kw in enumerate(seo['required_keywords'], 1):
                importance = "ğŸ”¥ CRITIQUE" if kw['importance'] >= 80 else "â­ IMPORTANT" if kw['importance'] >= 60 else "ğŸ“Œ STANDARD"
                print(f"   {i:2}. {kw['keyword']:<25} {kw['frequency']:>3}x {importance} (min:{kw['min_freq']}, max:{kw['max_freq']})")
        else:
            print("   âŒ Aucun mot-clÃ© obligatoire identifiÃ©")
        
        # MOTS-CLÃ‰S COMPLÃ‰MENTAIRES (Secondaires)
        print(f"\nğŸ’ MOTS-CLÃ‰S SECONDAIRES (COMPLÃ‰MENTAIRES):")
        if seo['complementary_keywords']:
            for i, kw in enumerate(seo['complementary_keywords'], 1):
                importance = "ğŸ”¥ CRITIQUE" if kw['importance'] >= 80 else "â­ IMPORTANT" if kw['importance'] >= 60 else "ğŸ“Œ STANDARD"
                print(f"   {i:2}. {kw['keyword']:<25} {kw['frequency']:>3}x {importance} (min:{kw['min_freq']}, max:{kw['max_freq']})")
        else:
            print("   âŒ Aucun mot-clÃ© complÃ©mentaire identifiÃ©")
        
        # EXPRESSIONS N-GRAMMES
        print(f"\nğŸ”— EXPRESSIONS CLÃ‰S (N-GRAMMES):")
        if seo['ngrams']:
            for i, ng in enumerate(seo['ngrams'], 1):
                importance = "ğŸ”¥ CRITIQUE" if ng['importance'] >= 80 else "â­ IMPORTANT" if ng['importance'] >= 60 else "ğŸ“Œ STANDARD"
                print(f"   {i:2}. \"{ng['ngram']}\" {ng['frequency']:>3}x {importance}")
        else:
            print("   âŒ Aucune expression identifiÃ©e")
        
        # QUESTIONS PAA
        print(f"\nâ“ QUESTIONS PEOPLE ALSO ASK:")
        if serp['paa_questions']:
            for i, question in enumerate(serp['paa_questions'][:5], 1):
                print(f"   {i}. {question}")
        else:
            print("   âŒ Aucune question PAA")
        
        # RECHERCHES ASSOCIÃ‰ES
        print(f"\nğŸ” RECHERCHES ASSOCIÃ‰ES:")
        if serp['related_searches']:
            for i, search in enumerate(serp['related_searches'][:8], 1):
                print(f"   {i}. {search}")
        else:
            print("   âŒ Aucune recherche associÃ©e")
        
        # ANALYSE MARCHÃ‰
        print(f"\nğŸ“ˆ ANALYSE MARCHÃ‰:")
        market = seo['market_analysis']
        if market:
            for content_type, stats in market.items():
                if isinstance(stats, dict) and 'count' in stats:
                    print(f"   ğŸ“„ {content_type}: {stats['count']} sites ({stats.get('percentage', 0):.1f}%)")
        
        # QUESTIONS GÃ‰NÃ‰RÃ‰ES
        if seo['generated_questions']:
            print(f"\nğŸ’¡ QUESTIONS GÃ‰NÃ‰RÃ‰ES PAR IA:")
            questions = seo['generated_questions'].split('\n')
            for i, q in enumerate(questions[:5], 1):
                if q.strip():
                    print(f"   {i}. {q.strip()}")
    
    async def extract_all_queries(self):
        """Extraction pour les 3 requÃªtes demandÃ©es"""
        
        queries = [
            "nettoyage aprÃ¨s inondation",
            "etat surface acier", 
            "aide implantation"
        ]
        
        print("ğŸš€ EXTRACTION RÃ‰ELLE DES MOTS-CLÃ‰S AVEC VALUESERP")
        print("=" * 80)
        
        # VÃ©rification API
        api_key = self.check_api_key()
        if not api_key:
            user_key = input("\nğŸ”‘ Veuillez entrer votre clÃ© API ValueSERP: ").strip()
            if user_key:
                os.environ['VALUESERP_API_KEY'] = user_key
                self.valueserp_service.api_key = user_key
                print(f"âœ… ClÃ© API configurÃ©e: {user_key[:10]}...{user_key[-4:]}")
            else:
                print("âŒ Aucune clÃ© API fournie, abandon.")
                return []
        
        all_results = []
        
        for i, query in enumerate(queries, 1):
            print(f"\n\nğŸ¯ REQUÃŠTE {i}/{len(queries)}")
            
            result = await self.extract_keywords_for_query(query)
            all_results.append(result)
            
            self.display_keyword_results(result)
            
            # Pause entre requÃªtes
            if i < len(queries):
                print(f"\nâ³ Pause de 3 secondes avant requÃªte suivante...")
                await asyncio.sleep(3)
        
        # RÃ©sumÃ© final
        self.display_final_summary(all_results)
        
        return all_results
    
    def display_final_summary(self, all_results: list):
        """Affiche un rÃ©sumÃ© comparatif final"""
        
        print(f"\n{'='*80}")
        print("ğŸ“Š RÃ‰SUMÃ‰ COMPARATIF DES 3 REQUÃŠTES")
        print("=" * 80)
        
        successful_results = [r for r in all_results if r['status'] == 'success']
        
        if not successful_results:
            print("âŒ Aucune requÃªte n'a abouti")
            return
        
        print(f"{'RequÃªte':<30} {'Primaires':<10} {'Secondaires':<12} {'Expressions':<12} {'Score':<6}")
        print("-" * 80)
        
        for result in successful_results:
            query = result['query'][:28]
            seo = result['seo_analysis']
            
            primary_count = len(seo['required_keywords'])
            secondary_count = len(seo['complementary_keywords'])  
            expressions_count = len(seo['ngrams'])
            score = seo['target_seo_score']
            
            print(f"{query:<30} {primary_count:<10} {secondary_count:<12} {expressions_count:<12} {score:<6}")
        
        # Insights
        print(f"\nğŸ’¡ INSIGHTS GLOBAUX:")
        
        # RequÃªte la plus riche en mots-clÃ©s
        richest = max(successful_results, key=lambda r: len(r['seo_analysis']['required_keywords']) + len(r['seo_analysis']['complementary_keywords']))
        total_kw = len(richest['seo_analysis']['required_keywords']) + len(richest['seo_analysis']['complementary_keywords'])
        print(f"   ğŸ† Plus riche en mots-clÃ©s: '{richest['query']}' ({total_kw} mots-clÃ©s)")
        
        # Score SEO le plus Ã©levÃ©
        highest_score = max(successful_results, key=lambda r: r['seo_analysis']['target_seo_score'])
        print(f"   ğŸ“ˆ Score SEO le plus Ã©levÃ©: '{highest_score['query']}' ({highest_score['seo_analysis']['target_seo_score']} points)")
        
        # Plus d'expressions
        most_expressions = max(successful_results, key=lambda r: len(r['seo_analysis']['ngrams']))
        print(f"   ğŸ”— Plus d'expressions: '{most_expressions['query']}' ({len(most_expressions['seo_analysis']['ngrams'])} expressions)")

async def main():
    extractor = RealKeywordExtractor()
    await extractor.extract_all_queries()

if __name__ == "__main__":
    asyncio.run(main())