#!/usr/bin/env python3
"""
Test du service LLM pour v√©rifier s'il fonctionne
"""
import asyncio
import os
import sys

# Ajouter le r√©pertoire courant au path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# Charger le .env
try:
    from dotenv import load_dotenv
    load_dotenv()
    print("‚úÖ Fichier .env charg√©")
except ImportError:
    print("‚ö†Ô∏è python-dotenv non disponible")

print("üîç V√âRIFICATION SERVICE LLM")

# Test simple des variables d'environnement
valueserp_key = os.getenv('VALUESERP_API_KEY')
openai_key = os.getenv('OPENAI_API_KEY') 
llm_enabled = os.getenv('LLM_FILTERING_ENABLED')
llm_debug = os.getenv('LLM_DEBUG_ENABLED')

print(f"VALUESERP_API_KEY: {'‚úÖ' if valueserp_key else '‚ùå'}")
print(f"OPENAI_API_KEY: {'‚úÖ' if openai_key else '‚ùå'}")
print(f"LLM_FILTERING_ENABLED: {llm_enabled}")
print(f"LLM_DEBUG_ENABLED: {llm_debug}")

# Test de l'import de config
try:
    from config import settings
    print(f"‚úÖ Config charg√©e")
    print(f"Settings LLM_FILTERING_ENABLED: {settings.LLM_FILTERING_ENABLED}")
    print(f"Settings OPENAI_API_KEY pr√©sente: {'‚úÖ' if settings.OPENAI_API_KEY else '‚ùå'}")
except Exception as e:
    print(f"‚ùå Erreur config: {e}")

# Test de l'import openai
try:
    from openai import OpenAI
    print("‚úÖ OpenAI import√©")
except ImportError as e:
    print(f"‚ùå OpenAI non disponible: {e}")

# Test du service LLM
try:
    from services.llm_keyword_filter import llm_filter
    print(f"‚úÖ Service LLM import√©")
    
    if llm_filter:
        print(f"Service activ√©: {llm_filter.enabled}")
        print(f"Statistiques: {llm_filter.get_daily_stats()}")
    else:
        print("‚ùå llm_filter est None")
        
except ImportError as e:
    print(f"‚ùå Erreur import service LLM: {e}")
except Exception as e:
    print(f"‚ùå Erreur g√©n√©rale service LLM: {e}")

# Test simple si tout est OK
try:
    if 'llm_filter' in locals() and llm_filter and llm_filter.enabled:
        print("üß™ TEST FILTRAGE...")
        
        test_keywords = ["collier", "chien", "avis", "france", "2024", "anti", "aboiement"]
        test_query = "collier anti aboiement chien"
        
        async def test():
            try:
                result = await llm_filter.filter_keywords_batch(test_keywords, test_query)
                print(f"‚úÖ Test r√©ussi: {len(test_keywords)} ‚Üí {len(result)} mots-cl√©s")
                print(f"Avant: {test_keywords}")
                print(f"Apr√®s: {result}")
            except Exception as e:
                print(f"‚ùå Erreur test LLM: {e}")
                import traceback
                traceback.print_exc()
        
        asyncio.run(test())
    else:
        print("‚ö†Ô∏è Pas de test - service non disponible")
        
except Exception as e:
    print(f"‚ùå Erreur test final: {e}")
    import traceback
    traceback.print_exc()