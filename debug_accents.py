#!/usr/bin/env python3
"""
Debug pour la d√©tection des accents
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from services.seo_analyzer import SEOAnalyzer

def debug_accent_detection():
    analyzer = SEOAnalyzer()
    
    # Test avec accents
    content = "La cr√©atin√´ monohydrat√© am√©liore. Cr√©atine monohydrate recommand√©."
    keyword = "cr√©atine monohydrate"
    
    print(f"üîç DEBUG D√âTECTION ACCENTS")
    print(f"Contenu: {content}")
    print(f"Mot-cl√©: {keyword}")
    print()
    
    # √âtape 1: Normalisation
    normalized_content = analyzer._normalize_for_detection(content)
    normalized_keyword = analyzer._normalize_for_detection(keyword)
    
    print(f"Contenu normalis√©: {normalized_content}")
    print(f"Mot-cl√© normalis√©: {normalized_keyword}")
    print()
    
    # √âtape 2: Tokenisation
    words = normalized_content.split()
    kw_parts = normalized_keyword.split()
    
    print(f"Mots: {words}")
    print(f"Parties mot-cl√©: {kw_parts}")
    print()
    
    # √âtape 3: Fen√™tre glissante
    candidates_count = 0
    k = len(kw_parts)
    
    print(f"Recherche de '{' '.join(kw_parts)}' dans le texte:")
    for i in range(len(words) - k + 1):
        window = words[i:i+k]
        match = all(words[i + j] == kw_parts[j] for j in range(k))
        print(f"  Position {i}: {window} ‚Üí {'‚úÖ MATCH' if match else '‚ùå'}")
        if match:
            candidates_count += 1
    
    print(f"\nR√©sultat final: {candidates_count} occurrences")
    
    # Test avec la m√©thode compl√®te
    result = analyzer._detect_keyword_hybrid(content, keyword)
    print(f"M√©thode compl√®te: {result} occurrences")
    
    # Debug validation contextuelle
    print(f"\nüîç DEBUG VALIDATION CONTEXTUELLE:")
    risky = ("'" in keyword) or ("-" in keyword) or (len(kw_parts) > 1)
    print(f"Cas complexe d√©tect√©: {risky}")
    
    if risky:
        valid_count_original = analyzer._validate_with_regex(content, keyword)
        valid_count_normalized = analyzer._validate_with_regex(normalized_content, normalized_keyword)
        print(f"Validation regex (original): {valid_count_original} occurrences")
        print(f"Validation regex (normalis√©): {valid_count_normalized} occurrences")
        print(f"Fen√™tre glissante: {candidates_count} occurrences")
        print(f"R√©sultat final: min({candidates_count}, {valid_count_normalized}) = {min(candidates_count, valid_count_normalized)}")

if __name__ == "__main__":
    debug_accent_detection()